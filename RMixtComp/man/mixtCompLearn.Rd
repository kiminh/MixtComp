% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MIXTCOMP_mixtCompLearn.R
\name{mixtCompLearn}
\alias{mixtCompLearn}
\alias{mixtCompPredict}
\title{Learn and predict using RMixtComp}
\usage{
mixtCompLearn(data, desc, algo = createAlgo(), nClass, crit = c("BIC",
  "ICL"))

mixtCompPredict(data, desc, algo = createAlgo(), resLearn,
  nClass = NULL)
}
\arguments{
\item{data}{a data.frame, a matrix or a named list containing the data (see \emph{Data format} section).}

\item{desc}{a named list containing models and hyperparameters (see \emph{Desc format} section).}

\item{algo}{a list containing the parameters of the SEM-Gibbs algorithm (see \emph{Details}).}

\item{nClass}{the number of class of the mixture model.}

\item{resLearn}{output of \emph{mixtCompCluster} (only for \emph{mixtCompPredict} function).}
}
\value{
A list containing 3 lists :
\describe{
 \item{strategy}{a copy of \emph{mcStrategy} parameter.}
 \item{mixture}{information about the mixture (see \emph{Details}).}
 \item{variable}{information about the estimated parameters and completed data (see \emph{Details}).}
}
}
\description{
Estimate the parameter of a mixture model or predict the cluster of new samples.
}
\details{
Details about the output object of \emph{mixtCompCluster} and \emph{mixtCompPredict} functions.

\emph{mcStrategy} is a list containing the different number of iterations for the algorithm. 
The algorithm is decomposed in a burn-in phase and a normal phase. 
Estimates from the burn-in phase are not shown in output.
\describe{
  \item{nbBurnInIter}{Number of iterations of the burn-in part of the SEM algorithm.}
  \item{nbIter}{Number of iterations of the SEM algorithm.}
  \item{nbGibbsBurnInIter}{Number of iterations of the burn-in part of the Gibbs algorithm.}
  \item{nbGibbsIter}{Number of iterations of the Gibbs algorithm.}
  \item{nInitPerClass}{Number of individuals used to initialize each cluster (default = 10).}
  \item{nSemTry}{Number of try of the algorithm for avoiding an error.}
}
You can use a void list, in this case, default values are used.
}
\section{Output object}{

The output list contains three elements \emph{mixture}, \emph{variable} and \emph{strategy}. \emph{mixture} is a list containing some criterion and some parameters. \emph{strategy} contains the parameter \emph{mcStrategy}. 
And \emph{variable} contains parameters and completed data.

The \emph{mixture} contains
\describe{
  \item{BIC}{value of BIC}
  \item{ICL}{value of ICL}
  \item{nbFreeParameters}{number of free parameters of the mixture}
  \item{lnObservedLikelihood}{observed loglikelihood}
  \item{lnCompletedLikelihood}{completed loglikelihood}
  \item{IDClass}{entropy used to compute the discriminative power (see code of \emph{plotDiscrimVbles})}
  \item{delta}{entropy used to compute the similarities between variables (see code of \emph{heatmapVbles})}
  \item{completedProbabilityLogBurnIn}{evolution of the completed log-probability during the burn-in period (can be used to check the convergence and determine the ideal number of iteration)}
  \item{completedProbabilityLogRun}{evolution of the completed log-probability  after the burn-in period (can be used to check the convergence and determine the ideal number of iteration)} 
  \item{runTime}{execution time in seconds} 
  \item{lnProbaGivenClass}{log-proportion + log-probability of x_i for each class}
}


The output list \emph{variable} contains 3 lists : \emph{data}, \emph{type} and \emph{param}. 

Each of these lists contains a list for each variable (the name of each list is the name of the variable) and for the class of samples (\emph{z_class}).
The \emph{type} list contains the model used for each variable. 

Each list of the \emph{data} list contains the completed data in the \emph{completed} element and some statistics about them (\emph{stat}). 

The estimated parameter can be found in the \emph{stat} element in the \emph{param} list (see Section \emph{View of an output object}). 
For more details about the parameters of each model, you can refer to \link{rnorm}, \link{rpois}, \link{rweibull}, \link{rnbinom}, \link{rmultinom}, or references in the \emph{References} section.
}

\section{View of an output object}{

Example of output object with variables named "categorical", "gaussian", "rank", "functional", "poisson", "nBinom" and "weibull" with respectively
 \emph{Multinomial}, \emph{Gaussian}, \emph{Rank_ISR}, \emph{Func_CS} (or \emph{Func_SharedAlpha_CS}), \emph{Poisson}, \emph{NegativeBinomial} and \emph{Weibull} as model. 

\tabular{lll}{
output  \cr
|_______ \tab algo \tab __ nbBurnInIter\cr
|        \tab      \tab |_ nbIter\cr
|        \tab      \tab |_ nbGibbsBurnInIter\cr
|        \tab      \tab |_ nbGibbsIter\cr
|        \tab      \tab |_ nInitPerClass\cr
|        \tab      \tab |_ nSemTry\cr
|        \tab      \tab |_ mode \cr
|        \tab      \tab |_ nInd  \cr
|        \tab      \tab |_ confidenceLevel  \cr
|        \tab      \tab |_ nClass \cr
| \cr
|_______ \tab mixture \tab __ BIC \cr
|        \tab         \tab |_ ICL\cr
|        \tab         \tab |_ lnCompletedLikelihood\cr
|        \tab         \tab |_ lnObservedLikelihood \cr
|        \tab         \tab |_ IDClass  \cr
|        \tab         \tab |_ delta  \cr
|        \tab         \tab |_ runTime \cr
|        \tab         \tab |_ nbFreeParameters \cr
|        \tab         \tab |_ completedProbabilityLogBurnIn \cr
|        \tab         \tab |_ completedProbabilityLogRun \cr
|        \tab         \tab |_ lnProbaGivenClass \cr
}
\tabular{llllll}{
|  \cr
|_______ \tab variable \tab __ type \tab __ z_class  \cr
         \tab          \tab |       \tab |_ categorical \cr
         \tab          \tab |       \tab |_ gaussian \cr
         \tab          \tab |       \tab |_ ...   \cr
         \tab          \tab |       \tab \cr
         \tab          \tab |_ data \tab __ z_class \tab __ completed\cr
         \tab          \tab |       \tab |          \tab |_ stat \cr
         \tab          \tab |       \tab |_ categorical \tab __ completed\cr
         \tab          \tab |       \tab |              \tab |_ stat \cr
         \tab          \tab |       \tab |_ ...         \tab \cr
         \tab          \tab |       \tab |_ functional \tab __ data\cr
         \tab          \tab |       \tab               \tab |_ time \cr
         \tab          \tab |       \tab \cr
         \tab          \tab |_ param \tab __ z_class \tab __ stat\cr
         \tab          \tab          \tab |          \tab |_ log \cr
         \tab          \tab          \tab |          \tab |_ paramStr \cr
         \tab          \tab          \tab |_ functional \tab __ alpha \tab __ stat\cr
         \tab          \tab          \tab |             \tab |        \tab |_ log \cr
         \tab          \tab          \tab |             \tab |_ beta  \tab __ stat\cr
         \tab          \tab          \tab |             \tab |        \tab |_ log \cr
         \tab          \tab          \tab |             \tab |_ sd    \tab __ stat\cr
         \tab          \tab          \tab |             \tab |        \tab |_ log \cr
         \tab          \tab          \tab |             \tab |_ paramStr \cr
         \tab          \tab          \tab |_ rank \tab __ mu \tab __ stat\cr
         \tab          \tab          \tab |       \tab |     \tab |_ log \cr
         \tab          \tab          \tab |       \tab |_ pi \tab __ stat\cr
         \tab          \tab          \tab |       \tab |     \tab |_ log \cr
         \tab          \tab          \tab |       \tab |_ paramStr \cr
         \tab          \tab          \tab |       \tab       \tab \cr
         \tab          \tab          \tab |_ gaussian \tab __ stat\cr
         \tab          \tab          \tab |           \tab |_ log \cr
         \tab          \tab          \tab |           \tab |_ paramStr \cr
         \tab          \tab          \tab |_ poisson  \tab __ stat\cr
         \tab          \tab          \tab |           \tab |_ log \cr
         \tab          \tab          \tab |           \tab |_ paramStr \cr
         \tab          \tab          \tab |_ ...

}
}

\examples{
\donttest{
data(simData)
 
# define the algorithm's parameters
algo <- list(nbBurnInIter = 100,
             nbIter = 100,
             nbGibbsBurnInIter = 50,
             nbGibbsIter = 50,
             nInitPerClass = 10,
             nSemTry = 20,
             confidenceLevel = 0.95)

# run RMixtCompt in unsupervised clustering mode + data as matrix
resLearn <- mixtCompLearn(simDataLearn$matrix, desc$unsupervised, algo, nbClass = 2:4)

# run RMixtCompt in supervised clustering mode + data as matrix
resLearn <- mixtCompLearn(simDataLearn$data.frame, desc$supervised, algo, nbClass = 2:4)

# run RMixtCompt in predict mode + data as list
resLearn <- mixtCompPredict(simDataPredict$list, desc$unsupervised, algo, nbClass = 2)

}



}
\references{
Julien Jacques, Christophe Biernacki. \emph{Model-based clustering for multivariate partial ranking data}. Journal of Statistical Planning and Inference, Elsevier, 2014, 149, pp.201-217.
Allou Samé, Faicel Chamroukhi, Gérard Govaert, Patrice Aknin. \emph{Model-based clustering and segmentation of time series with change in regime}. Advances in Data Analysis and Classification, 2011, 5(4):301-321
}
