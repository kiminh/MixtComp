\documentclass[a4paper,11pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{fullpage}
\usepackage{hyperref}

% Title Page
\title{MixComp Specification: Framework and Developer}

\begin{document}
\maketitle
\tableofcontents

\begin{abstract}
This is a mini-report for global architecture of MixComp. We will make use of two terms
"framework" and "developer". The framework provides a unified development
environment whereas developer will refer to the coding part that will make use of
the framework (without modifying the framework) to realize new mixture laws. In
practice, this is just a separation of Interface (framework) and Implementation (developer). 
\end{abstract}
\section{Framework Introduction}
The idea of unified framework is to integrate the existing and future clustering models.
The things that can be expected from the framework are:
\begin{enumerate}
\item Unified environment for composite mixture model based on the independence assumption (amongst different mixture models).
\item Abstract(Interface) plug-in class that must be derived by developer to develop a
new mixture law.
\item Facilitate creation of Rpackage, Web Interface, GUI and other High level functionalities.
\item Facilitate parallelization using distributed and shared memory models.
\item Take input from user and run the whole software.
\end{enumerate}

The developer is not expected to change the functionalities provided by this framework
but can only provide concrete behavior to these functionalities. Any new functionalities
should be first introduced in the framework. Hence the framework is expected to evolve
with time. The developer is only expected to provide all the low level implementations
needed by the framework without worrying about how these functionalities will be
brought together to realize a composite mixture model. Hence in short, the developer
can concentrate on development of existing and new mixture laws without worrying
about how to run them in integrated(composite) environment. The developer is free
to chose it's development environment (including numerical libraries for example
STK++, Eigen, Lapack or anything more suitable to developer needs) and in no way
will be restricted by framework. For example, a developer can re-factor their
existing codes and fit them into the framework (Quentin existing codes will be
a good test for it) or one can re-implement from scratch  using this framework
(development of simple models including Bernoulli and Gaussian(with diagonal
co-variance matrix) with Serge on STK++ platform will be a good test for it).
This is the most interesting feature of this architecture as it will allow to
independently develop new models.

\section{Plug-in Specification}

The Plug-in specification includes description on how to define a new mixture law using the framework.
To create a new mixture law, the developer 
must create a new class inherited from IDeveloper class. The IDeveloper class contains Interface methods that 
are mostly based on SEM-gibbs algorithm to allow generalization. Most of these methods are abstract, hence the developer must provide
concrete implementation in the derived class for them.
The functions ending with "() = 0" are abstract. The functions ending with "() \{\}" do nothing by default and the functions
ending with "()" are already implemented in framework (the developer can of-course
overwrite them in some cases for performance reasons.) The following interface functions are available:
\begin{itemize}
\item {\bf virtual void initializeStep() = 0} \\
This function must be use for initialization stuffs including initialize of all
the parameters. The function accepts one argument for randomly initialized class
labels. This method will be called only once in the very beginning.
\item {\bf virtual void imputationStep() \{\}}\\
This function should be used for Imputation of data.
\item {\bf virtual void samplingStep() = 0} \\
This function must be used for simulation of all the latent variables and/or missing data
excluding class labels. The class labels will be simulated by the framework itself because to do so
we have to take into account all the mixture laws. 
\item {\bf virtual void paramUpdateStep() = 0}\\
This function is equivalent to Mstep. This function must be defined by developer to update parameters.
\item {\bf virtual void finalizeStep() \{\}}\\
This step can be used by developer to finalize any thing. It will be called only once after we
finish running the SEM-gibbs algorithm.
\item {\bf virtual double posteriorProbability(int sample\_num,int Cluster\_num) = 0}\\
This function must be defined by developer to return the probability for corresponding sample and cluster.
\item {\bf virtual double** allPosteriorProbabilties()}\\
This function will be defined in framework using {\bf posteriorProbability} function, but developer
can override this function for performance reasons.
\item {\bf virtual double logLikelihood() const = 0}\\
This should be defined to return the log-likelihood value to be used by selection criteria.
\item {\bf virtual int freeParameters() const = 0}\\
This should be used to return the number of free parameters to be used by selection criteria.
\item {\bf virtual void setData() = 0}\\
This function must be defined to set the data into your data containers. To facilitate data handling, framework provide templated functions,
that can be called directly to get the user data. This is defined in more details in section \ref{datahandling}.
\end{itemize}

There is no notion of Estep, Mstep, Sstep and Cstep in the plug-in part. These names will be used inside the framework to make
it generic enough to expand for future. There are certain functions that are already defined in the IDeveloper 
class and hence can be called directly inside the inherited class. 
They are enumerated below:
\begin{itemize}
 \item {\bf int nbCluster()}\\
You should call this function to get the number of clusters.
\item {\bf double** conditionalProbabilities()}\\
\item {\bf int* classLabels()}\\
\item {\bf double* proportions()}\\
\end{itemize}

The IDeveloper class also contained following member variables, hence you must not redefine/redeclare them inside your inherited class.
\begin{itemize}
 \item 
\end{itemize}

\subsection{Data Handling}
\label{datahandling}
\section{stk++ Statistical Models}

A (multivariate) statistical model in stk++ is a


\appendix

\section{Coding conventions}

For the coding we use the java coding convention. All data members
are defined with an underscore at the end of their name, like \verb+data_+.

Data members referring to pointer start with \verb+p_+

All alternatives should be enclosed in \verb+enum+.

The notations proposed in this document can be modified if needed
or enclosed in namespace in order to avoid name collision.


\section{Components behaviors}
\subsection{Algorithms}

The algorithms will be:
\begin{verbatim}
enum Algo
{
  em_,
  cem_,
  sem_,
  mcem_,
  exact_
}
\end{verbatim}

The priority is to implement the \verb+*em+ versions, the \verb+exact_+ is just there in case of, but
should not be implemented. Should we add stochastic minimization algorithms ?

\subsection{Stopping criteria}

The stopping criteria will be:
\begin{verbatim}
enum StopCriteria
{
  deltaLnLikelihood_,
  deltaPostProbabilities_,
  deltaParameters_,
  nbIterMax_
}
\end{verbatim}
It should be possible to mix different criteria, for example
\verb+deltaLnLikelihood_|nbIterMax_+ mean that we want to stop the iteration when one
of the criteria is true.

\subsection{Data initialization}

The initialization of the algorithm will be:
\begin{verbatim}
enum Initialization
{
  randomPartition_,
  randomParameters_,
  givenPartition_,
  givenPosteriorProbabiblity_,
  givenParameters_
}
\end{verbatim}

Did i forget a method for initialization ? The random cases are the priority.
In case of heterogeneous distributions it will be difficult to find a way for initialization with
given parameters.

\subsection{Strategies}

A strategy is composed of three parts:
\begin{enumerate}
  \item multiple initializations,
  \item for each initialization a short run,
  \item A long run.
\end{enumerate}

\subsubsection{short runs}

A short run will be an arbitrary number of sequence \verb+(Algo_, StopCriteria)+. For example:
\begin{verbatim}
{(sem_, 1000), (cem_, 0.01|1000)}, {(em, 0.01)}
\end{verbatim}
mean that in a short run, there is 1000 iterations of the SEM algorithm, and at most 1000 iterations
of CEM that will be stopped  if some other criterion have a delta less than 0.01 and finally iterations of the EM
until the delta of some criteria is less than 0.01.

\subsubsection{long run}

A long run is initialized with the better of the short run and a StopCriteria.
If there is no short run, with an initialization.

\subsection{Model Selection Criteria}
The model criteria will be:
\begin{verbatim}
enum Criteria
{
  aic_,
  bic_,
  icl_,
  cv_,
  penExtern_
}
\end{verbatim}
It should be possible to let an user to define its own penalization criteria (\verb+penExtern_+ option).
Should we add cross-validation ?

\end{document}
